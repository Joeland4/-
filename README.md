# -
深度学习常见问题小笔记
【L1&L2正则化】：为什么减少过拟合？加入正则化项，在最小化经验误差的情况下，可以让我们选择解更简单（趋向于0）的解。详见：https://zhuanlan.zhihu.com/p/35356992
【Scaler】：MinMax还是Standard？Standard能够避免异常值带来影响。详见：https://www.zhihu.com/question/20467170/answer/839255695
【Norm】：
【Activation function】：
【Learning rate】：
【Gradient】：
【Position embedding】：
【】：
